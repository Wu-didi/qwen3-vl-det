#!/usr/bin/env python3
"""
GRPO è®­ç»ƒé€Ÿåº¦ç›‘æ§å·¥å…·

å®æ—¶ç›‘æ§è®­ç»ƒé€Ÿåº¦ï¼Œä¼°ç®—å‰©ä½™æ—¶é—´ï¼Œæä¾›ä¼˜åŒ–å»ºè®®

Usage:
    python scripts/monitor_grpo_speed.py --log outputs/qwen3vl_grpo_trl/training_log.json
    python scripts/monitor_grpo_speed.py --log outputs/qwen3vl_grpo_trl/training_log.json --watch
"""

import os
import json
import time
import argparse
from datetime import datetime, timedelta
from pathlib import Path


def load_log(log_path):
    """åŠ è½½è®­ç»ƒæ—¥å¿—"""
    try:
        with open(log_path, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        return None
    except json.JSONDecodeError:
        return None


def analyze_speed(log):
    """åˆ†æè®­ç»ƒé€Ÿåº¦"""
    if not log:
        return None

    train_history = log.get('train_history', [])
    if len(train_history) < 2:
        return None

    # è·å–é…ç½®
    config = log.get('config', {})
    gradient_accumulation = config.get('gradient_accumulation_steps', 4)
    batch_size = config.get('batch_size', 1)
    samples_per_step = gradient_accumulation * batch_size

    # è®¡ç®—é€Ÿåº¦
    total_steps = train_history[-1]['step']
    total_samples = total_steps * samples_per_step

    # ä¼°ç®—æ—¶é—´ï¼ˆå‡è®¾å‡åŒ€åˆ†å¸ƒï¼‰
    # è¿™é‡Œæˆ‘ä»¬æ— æ³•è·å–çœŸå®æ—¶é—´ï¼Œåªèƒ½æ ¹æ®è®°å½•ç‚¹æ•°é‡ä¼°ç®—
    num_logs = len(train_history)
    logging_steps = config.get('logging_steps', 10)

    return {
        'total_steps': total_steps,
        'total_samples': total_samples,
        'num_logs': num_logs,
        'samples_per_step': samples_per_step,
        'logging_steps': logging_steps,
        'config': config,
    }


def print_status(log_path, clear_screen=False):
    """æ‰“å°è®­ç»ƒçŠ¶æ€"""
    if clear_screen:
        os.system('clear' if os.name != 'nt' else 'cls')

    print("=" * 70)
    print("GRPO è®­ç»ƒé€Ÿåº¦ç›‘æ§")
    print("=" * 70)
    print(f"æ—¥å¿—æ–‡ä»¶: {log_path}")
    print(f"æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    log = load_log(log_path)

    if not log:
        print("âŒ æ— æ³•åŠ è½½è®­ç»ƒæ—¥å¿—")
        print()
        print("å¯èƒ½åŸå› ï¼š")
        print("  1. è®­ç»ƒè¿˜æœªå¼€å§‹")
        print("  2. æ—¥å¿—æ–‡ä»¶è·¯å¾„ä¸æ­£ç¡®")
        print("  3. æ—¥å¿—æ–‡ä»¶æ ¼å¼é”™è¯¯")
        return

    # åˆ†æé€Ÿåº¦
    speed_info = analyze_speed(log)

    if not speed_info:
        print("â³ è®­ç»ƒåˆšå¼€å§‹ï¼Œæ•°æ®ä¸è¶³")
        print()
        print("å»ºè®®ï¼šç­‰å¾… 10-20 åˆ†é’Ÿåå†æŸ¥çœ‹")
        return

    # æ˜¾ç¤ºé…ç½®
    config = speed_info['config']
    print("ğŸ“‹ è®­ç»ƒé…ç½®")
    print("-" * 70)
    print(f"  æ¨¡å‹: {config.get('model_path', 'N/A')}")
    print(f"  å›¾ç‰‡å¤§å°: {config.get('max_image_size', 'N/A')}px")
    print(f"  ç”Ÿæˆæ•°é‡: {config.get('num_generations', 'N/A')}")
    print(f"  Batch Size: {config.get('batch_size', 'N/A')}")
    print(f"  æ¢¯åº¦ç´¯ç§¯: {config.get('gradient_accumulation_steps', 'N/A')}")
    print(f"  LoRA Rank: {config.get('lora_r', 'N/A')}")
    print()

    # æ˜¾ç¤ºè¿›åº¦
    print("ğŸ“Š è®­ç»ƒè¿›åº¦")
    print("-" * 70)
    print(f"  å·²å®Œæˆæ­¥æ•°: {speed_info['total_steps']}")
    print(f"  å·²å¤„ç†æ ·æœ¬: {speed_info['total_samples']}")
    print(f"  è®°å½•ç‚¹æ•°é‡: {speed_info['num_logs']}")
    print()

    # æ˜¾ç¤ºæœ€æ–°æŒ‡æ ‡
    train_history = log.get('train_history', [])
    if train_history:
        latest = train_history[-1]
        print("ğŸ“ˆ æœ€æ–°æŒ‡æ ‡")
        print("-" * 70)
        for key, value in latest.items():
            if key not in ['step', 'epoch', 'samples']:
                if isinstance(value, float):
                    print(f"  {key}: {value:.4f}")
                else:
                    print(f"  {key}: {value}")
        print()

    # æ˜¾ç¤ºéªŒè¯ç»“æœ
    val_history = log.get('val_history', [])
    if val_history:
        latest_val = val_history[-1]
        print("âœ… æœ€æ–°éªŒè¯ç»“æœ")
        print("-" * 70)
        for key, value in latest_val.items():
            if key not in ['step', 'epoch', 'samples']:
                if isinstance(value, float):
                    print(f"  {key}: {value:.4f}")
                else:
                    print(f"  {key}: {value}")
        print()

    # æ˜¾ç¤ºæœ€ä½³æ£€æŸ¥ç‚¹
    best_checkpoint = log.get('best_checkpoint')
    if best_checkpoint:
        print("ğŸ† æœ€ä½³æ£€æŸ¥ç‚¹")
        print("-" * 70)
        print(f"  Step: {best_checkpoint.get('step', 'N/A')}")
        print(f"  Epoch: {best_checkpoint.get('epoch', 'N/A')}")
        for key, value in best_checkpoint.items():
            if key not in ['step', 'epoch', 'path', 'samples']:
                if isinstance(value, float):
                    print(f"  {key}: {value:.4f}")
        print(f"  è·¯å¾„: {best_checkpoint.get('path', 'N/A')}")
        print()

    # ä¼˜åŒ–å»ºè®®
    print("ğŸ’¡ ä¼˜åŒ–å»ºè®®")
    print("-" * 70)

    suggestions = []

    # æ£€æŸ¥å›¾ç‰‡å¤§å°
    max_image_size = config.get('max_image_size', 512)
    if max_image_size >= 1024:
        suggestions.append("âš ï¸  å›¾ç‰‡å¤§å°è¿‡å¤§ (1024px)ï¼Œå»ºè®®é™ä½åˆ° 512px ä»¥æå‡ 4 å€é€Ÿåº¦")
    elif max_image_size >= 768:
        suggestions.append("ğŸ’¡ å›¾ç‰‡å¤§å°è¾ƒå¤§ (768px)ï¼Œå¯é™ä½åˆ° 512px ä»¥æå‡ 2 å€é€Ÿåº¦")

    # æ£€æŸ¥æ¨¡å‹å¤§å°
    model_path = config.get('model_path', '')
    if '8B' in model_path or '7B' in model_path:
        suggestions.append("ğŸ’¡ ä½¿ç”¨å¤§æ¨¡å‹ (8B)ï¼Œå¯æ”¹ç”¨ 2B æ¨¡å‹ä»¥æå‡ 4 å€é€Ÿåº¦")

    # æ£€æŸ¥ç”Ÿæˆæ•°é‡
    num_generations = config.get('num_generations', 4)
    if num_generations >= 6:
        suggestions.append("ğŸ’¡ ç”Ÿæˆæ•°é‡è¾ƒå¤š (6+)ï¼Œå¯é™ä½åˆ° 4 ä»¥æå‡é€Ÿåº¦")

    # æ£€æŸ¥éªŒè¯é¢‘ç‡
    eval_steps = config.get('eval_steps', 0)
    if eval_steps > 0 and eval_steps < 500:
        suggestions.append("ğŸ’¡ éªŒè¯é¢‘ç‡è¾ƒé«˜ï¼Œå¯è®¾ç½® EVAL_STEPS=0 ä»¥æå‡ 1.5 å€é€Ÿåº¦")

    # æ£€æŸ¥ LoRA rank
    lora_r = config.get('lora_r', 64)
    if lora_r >= 64:
        suggestions.append("ğŸ’¡ LoRA rank è¾ƒå¤§ (64+)ï¼Œå¯é™ä½åˆ° 32 ä»¥æå‡ ~20% é€Ÿåº¦")

    if suggestions:
        for suggestion in suggestions:
            print(f"  {suggestion}")
    else:
        print("  âœ… é…ç½®å·²ä¼˜åŒ–ï¼Œæ— æ˜æ˜¾ç“¶é¢ˆ")

    print()
    print("=" * 70)


def watch_mode(log_path, interval=60):
    """ç›‘æ§æ¨¡å¼"""
    print("è¿›å…¥ç›‘æ§æ¨¡å¼ï¼ˆæŒ‰ Ctrl+C é€€å‡ºï¼‰")
    print(f"åˆ·æ–°é—´éš”: {interval} ç§’")
    print()

    try:
        while True:
            print_status(log_path, clear_screen=True)
            time.sleep(interval)
    except KeyboardInterrupt:
        print("\n\nç›‘æ§å·²åœæ­¢")


def main():
    parser = argparse.ArgumentParser(description="GRPO è®­ç»ƒé€Ÿåº¦ç›‘æ§")
    parser.add_argument("--log", type=str, required=True,
                        help="è®­ç»ƒæ—¥å¿—æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--watch", action="store_true",
                        help="ç›‘æ§æ¨¡å¼ï¼ˆå®æ—¶åˆ·æ–°ï¼‰")
    parser.add_argument("--interval", type=int, default=60,
                        help="ç›‘æ§æ¨¡å¼åˆ·æ–°é—´éš”ï¼ˆç§’ï¼‰")

    args = parser.parse_args()

    if args.watch:
        watch_mode(args.log, args.interval)
    else:
        print_status(args.log)


if __name__ == "__main__":
    main()
